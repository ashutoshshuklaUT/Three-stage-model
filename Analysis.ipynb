{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b0b72",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from heuristic import *\n",
    "from utils import *\n",
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_columns',500)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "%matplotlib inline\n",
    "\n",
    "def get_df_for_heuristic():\n",
    "    df = pd.read_csv(\"/Users/ashutoshshukla/Desktop/ThreeStageModel/data/192_Scenario/Final_Input1.csv\")\n",
    "    directions = [\"w\", \"wnw\", \"nw\", \"nnw\", \"n\", \"nne\"]\n",
    "    categories = [\"2\", \"3\", \"4\", \"5\"]\n",
    "    forward_speeds = [\"05\", \"10\", \"15\", \"25\"]\n",
    "    lister = []\n",
    "    for i in directions:\n",
    "        for j in range(len(categories)):\n",
    "            for k in range(len(forward_speeds)):\n",
    "                lister.append(\"max_flood_level_\" + i +\"_\" + categories[j] + \"_\" + forward_speeds[k])\n",
    "    df = df[list(df.columns[0:9]) + lister]\n",
    "    df_sub = df[[\"SubNum\", \"load\"]].groupby(\"SubNum\").sum()\n",
    "    df_flood = df[[\"SubNum\"] + lister]\n",
    "    df_flood = df_flood.drop_duplicates().set_index(\"SubNum\") # drop duplicates\n",
    "    df_flood = df_flood.loc[(df_flood.sum(axis=1) != 0), :] # drop substations that are not flooded\n",
    "    \"\"\"df_sub has load demand for all the substations\"\"\"\n",
    "    \"\"\"df_flood has only flooded substations\"\"\"\n",
    "    return df, df_sub, df_flood\n",
    "\n",
    "def return_model_scenarios():\n",
    "    directions = [\"w\", \"wnw\", \"nw\", \"nnw\", \"n\", \"nne\"]\n",
    "    categories = [\"2\", \"3\", \"4\", \"5\"]\n",
    "    forward_speeds = [\"05\", \"10\", \"15\", \"25\"]\n",
    "    model_scenarios = {}\n",
    "    counter = 0\n",
    "    for i in directions:\n",
    "        for j in range(len(categories)-1):\n",
    "            for k in range(len(forward_speeds)-1):\n",
    "                lister = []\n",
    "                lister.append(\"max_flood_level_\" + i +\"_\" + categories[j] + \"_\" + forward_speeds[k])\n",
    "                lister.append(\"max_flood_level_\" + i +\"_\" + categories[j] + \"_\" + forward_speeds[k+1])\n",
    "                #lister.append(\"max_flood_level_\" + i +\"_\" + categories[j] + \"_\" + forward_speeds[k+2])\n",
    "                lister.append(\"max_flood_level_\" + i +\"_\" + categories[j+1] + \"_\" + forward_speeds[k])\n",
    "                lister.append(\"max_flood_level_\" + i +\"_\" + categories[j+1] + \"_\" + forward_speeds[k+1])\n",
    "                #lister.append(\"max_flood_level_\" + i +\"_\" + categories[j+1] + \"_\" + forward_speeds[k+2])\n",
    "                model_scenarios[counter] = lister\n",
    "                counter = counter + 1\n",
    "    return model_scenarios\n",
    "\n",
    "def cmap_discretize(cmap, N):\n",
    "    \"\"\"Return a discrete colormap from the continuous colormap cmap.\n",
    "\n",
    "        cmap: colormap instance, eg. cm.jet. \n",
    "        N: number of colors.\n",
    "\n",
    "    Example\n",
    "        x = resize(arange(100), (5,100))\n",
    "        djet = cmap_discretize(cm.jet, 5)\n",
    "        imshow(x, cmap=djet)\n",
    "    \"\"\"\n",
    "\n",
    "    if type(cmap) == str:\n",
    "        cmap = plt.get_cmap(cmap)\n",
    "    colors_i = np.concatenate((np.linspace(0, 1., N), (0.,0.,0.,0.)))\n",
    "    colors_rgba = cmap(colors_i)\n",
    "    indices = np.linspace(0, 1., N+1)\n",
    "    cdict = {}\n",
    "    for ki,key in enumerate(('red','green','blue')):\n",
    "        cdict[key] = [ (indices[i], colors_rgba[i-1,ki], colors_rgba[i,ki])\n",
    "                       for i in range(N+1) ]\n",
    "    # Return colormap object.\n",
    "    return mcolors.LinearSegmentedColormap(cmap.name + \"_%d\"%N, cdict, 1024)\n",
    "\n",
    "df, df_sub, df_flood = get_df_for_heuristic()\n",
    "model_scenarios = return_model_scenarios()\n",
    "\n",
    "with open('optimization_solution_list.pickle', 'rb') as handle:\n",
    "    optimization_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26180829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \u001b[32mfinal\u001b[m\n",
      "  main\u001b[m\n",
      "  paper\u001b[m\n"
     ]
    }
   ],
   "source": [
    "! git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249de110",
   "metadata": {},
   "outputs": [],
   "source": [
    "voll = 6000\n",
    "df_plot = pd.DataFrame(index=df_flood.index, columns=np.arange(0,54,1))\n",
    "lister = []\n",
    "for i in df_plot.index:\n",
    "    for j in df_plot.columns:\n",
    "        temp = str(i) + \"_\" + str(j)\n",
    "        td_value = optimization_list[voll][1][temp]\n",
    "        flood = df_flood.loc[i, model_scenarios[j]].max()\n",
    "        if td_value == 0:\n",
    "            if flood == 0:\n",
    "                df_plot.loc[i,j] = 0.0\n",
    "            else:\n",
    "                df_plot.loc[i,j] = 1.0\n",
    "        else:\n",
    "            if td_value > flood:\n",
    "                df_plot.loc[i,j] = 2.0\n",
    "            elif td_value == flood:\n",
    "                df_plot.loc[i,j] = 3.0\n",
    "            else:\n",
    "                df_plot.loc[i,j] = 4.0\n",
    "    if optimization_list[voll][0][i] > 0:\n",
    "        lister.append(5.0)\n",
    "    else:\n",
    "        lister.append(6.0)\n",
    "    \n",
    "df_plot[\"hardening\"] = lister\n",
    "df_plot[\"hardening1\"] = lister\n",
    "df_plot[\"hardening2\"] = lister\n",
    "df_plot[\"hardening3\"] = lister\n",
    "\n",
    "colormap_mapping = {\n",
    "    0.0: 'red',\n",
    "    1.0: 'green',\n",
    "    2.0: 'blue',\n",
    "    3.0: 'purple',\n",
    "    4.0: 'orange',\n",
    "    5.0: \"black\",\n",
    "    6.0: \"yellow\"\n",
    "}\n",
    "colors = [colormap_mapping[i] for i in range(7)]\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.matshow(df_plot.iloc[:,:].values.astype(float),cmap=cmap)\n",
    "cb = plt.colorbar(shrink=0.8)\n",
    "labels = np.arange(0,7, 0.2)\n",
    "loc    = [0.45,1.3,2.1,3,3.8,4.7,5.6]\n",
    "cb.set_ticks(loc)\n",
    "l1 = [\"td = max_flood = 0\", \"td = 0 < max_flood\", \"td > max_flood > 0\", \"td = max_flood > 0\",\n",
    "      \"0 <td < max_flood\", \"hardened\", \"not hardened\"]\n",
    "      \n",
    "cb.set_ticklabels(l1)\n",
    "plt.tick_params(which = 'both', size = 0, labelsize = 0)\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"Preparedness Models\")\n",
    "plt.ylabel(\"Substations\")\n",
    "#plt.savefig(\"output_plots/voll_variation_\" + str(voll) + \".pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fed6630",
   "metadata": {},
   "source": [
    "# Flood Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae15fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.matshow(df_flood.iloc[:,:].values.astype(float))\n",
    "cb = plt.colorbar(shrink=0.8)\n",
    "\n",
    "#plt.savefig(\"output_plots/flooding.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d7cbd",
   "metadata": {},
   "source": [
    "# General method for any kind of run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list = [250,500,1000,2000,3000,4000,5000,6000]\n",
    "\n",
    "for voll_c in model_name_list:\n",
    "    print(voll_c)\n",
    "    model_name = \"modified_td_coordination_\" + str(voll_c)\n",
    "    main_path = \"/Users/ashutoshshukla/Downloads/\" + model_name + \"/\"\n",
    "\n",
    "    with open(main_path + \"model_params.json\", 'r') as f:\n",
    "        params = json.load(f)   \n",
    "    params[\"path_to_input\"] = os.getcwd() + \"/data/192_Scenario/\"\n",
    "\n",
    "    with open(main_path + \"model_scenarios.json\", 'r') as f:\n",
    "        model_scenarios_string = json.load(f)\n",
    "\n",
    "    model_scenarios = {}\n",
    "    for k in model_scenarios_string:\n",
    "        model_scenarios[int(k)] = model_scenarios_string[k]\n",
    "\n",
    "    base_model = three_stage_model(params, model_scenarios)\n",
    "    base_model.model.update()\n",
    "    sol_path = main_path + \"solution.sol\"\n",
    "    base_model.model.read(sol_path)\n",
    "    base_model.model.update()\n",
    "\n",
    "    hardening_decisions = {}\n",
    "    tiger_dam_decisions = {}\n",
    "\n",
    "    for sub_id in df_flood.index:\n",
    "        hardening_decisions[sub_id] = int(base_model.x_mit[sub_id].Start*params[\"mit_level\"])\n",
    "    for sub_id in df_flood.index:\n",
    "        for j in model_scenarios:\n",
    "            tiger_dam_decisions[str(sub_id) + \"_\" + str(j)] = int(base_model.x_prep[sub_id,j].Start*params[\"prep_level\"])\n",
    "\n",
    "\n",
    "    df_plot = pd.DataFrame(index=df_flood.index, columns=np.arange(0,54,1))\n",
    "    lister = []\n",
    "    for i in df_plot.index:\n",
    "        for j in df_plot.columns:\n",
    "            temp = str(i) + \"_\" + str(j)\n",
    "            td_value = tiger_dam_decisions[temp]\n",
    "            flood = df_flood.loc[i, model_scenarios[j]].max()\n",
    "            if td_value == 0:\n",
    "                if flood == 0:\n",
    "                    df_plot.loc[i,j] = 0.0\n",
    "                else:\n",
    "                    df_plot.loc[i,j] = 1.0\n",
    "            else:\n",
    "                if td_value > flood:\n",
    "                    df_plot.loc[i,j] = 2.0\n",
    "                elif td_value == flood:\n",
    "                    df_plot.loc[i,j] = 3.0\n",
    "                else:\n",
    "                    df_plot.loc[i,j] = 4.0\n",
    "        if hardening_decisions[i] > 0:\n",
    "            lister.append(5.0)\n",
    "        else:\n",
    "            lister.append(6.0)\n",
    "\n",
    "    df_plot[\"hardening\"] = lister\n",
    "    df_plot[\"hardening1\"] = lister\n",
    "    df_plot[\"hardening2\"] = lister\n",
    "    df_plot[\"hardening3\"] = lister\n",
    "\n",
    "    colormap_mapping = {\n",
    "        0.0: 'red',\n",
    "        1.0: 'green',\n",
    "        2.0: 'blue',\n",
    "        3.0: 'purple',\n",
    "        4.0: 'orange',\n",
    "        5.0: \"black\",\n",
    "        6.0: \"yellow\"\n",
    "    }\n",
    "    colors = [colormap_mapping[i] for i in range(7)]\n",
    "    cmap = mpl.colors.ListedColormap(colors)\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.matshow(df_plot.iloc[:,:].values.astype(float),cmap=cmap)\n",
    "    cb = plt.colorbar(shrink=0.8)\n",
    "    labels = np.arange(0,7, 0.2)\n",
    "    loc    = [0.45,1.3,2.1,3,3.8,4.7,5.6]\n",
    "    cb.set_ticks(loc)\n",
    "    l1 = [\"td = max_flood = 0\", \"td = 0 < max_flood\", \"td > max_flood > 0\", \"td = max_flood > 0\",\n",
    "          \"0 <td < max_flood\", \"hardened\", \"not hardened\"]\n",
    "\n",
    "    cb.set_ticklabels(l1)\n",
    "    plt.tick_params(which = 'both', size = 0, labelsize = 0)\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel(\"Preparedness Models\")\n",
    "    plt.ylabel(\"Substations\")\n",
    "    plt.savefig(\"output_plots/\" + model_name + \".pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67315e4",
   "metadata": {},
   "source": [
    "# Solution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309ebd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_analysis(main_path):    \n",
    "    with open(main_path + \"model_params.json\", 'r') as f:\n",
    "        params = json.load(f)   \n",
    "    params[\"path_to_input\"] = os.getcwd() + \"/data/192_Scenario/\"\n",
    "    with open(main_path + \"model_scenarios.json\", 'r') as f:\n",
    "        model_scenarios_string = json.load(f)\n",
    "    model_scenarios = {}\n",
    "    for k in model_scenarios_string:\n",
    "        model_scenarios[int(k)] = model_scenarios_string[k]\n",
    "    base_model = three_stage_model(params, model_scenarios)\n",
    "    base_model.model.update()\n",
    "    sol_path = main_path + \"solution.sol\"\n",
    "    base_model.model.read(sol_path)\n",
    "    base_model.model.update()\n",
    "\n",
    "    hardening_decisions = {}\n",
    "    tiger_dam_decisions = {}\n",
    "\n",
    "    for sub_id in df_flood.index:\n",
    "        hardening_decisions[sub_id] = int(base_model.x_mit[sub_id].Start*params[\"mit_level\"])\n",
    "    for sub_id in df_flood.index:\n",
    "        for j in model_scenarios:\n",
    "            tiger_dam_decisions[str(sub_id) + \"_\" + str(j)] = int(base_model.x_prep[sub_id,j].Start*params[\"prep_level\"])\n",
    "    \n",
    "    return hardening_decisions, tiger_dam_decisions, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e27ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = \"/Users/ashutoshshukla/Downloads/modified_flexible_mit_24/\"\n",
    "hard_18, td_18, base_18 = model_analysis(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4763a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = \"/Users/ashutoshshukla/Downloads/modified_td_voll_6000/\"\n",
    "hard, td, base = model_analysis(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f70a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_lister = []\n",
    "\n",
    "for i in hard_18:\n",
    "    main_lister.append([hard_18[i], hard[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba5c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(main_lister)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebec965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(main_lister)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24773bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"round\"] = df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c31d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1[\"round\"] > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8605f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flood.loc[[327, 929, 1025, 1084, 1104], :].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96230f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1[1] > df1[\"round\"]][[1, \"round\"]]\n",
    "\n",
    "# 8 instances where coarse model did not harden substation which implies here we will lose power "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32191e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.loc[[327, 349, 929, 952, 979, 1025, 1084, 1104],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c251a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.index = list(hardening_decisions.keys())\n",
    "\n",
    "df2 = df1[df1[1] < df1[\"round\"]][[1, \"round\"]]\n",
    "\n",
    "pd.Series(df2[\"round\"] - df[1]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4fd1eb",
   "metadata": {},
   "source": [
    "* 29 substations are over hardened. Here we put $9.7M extra. But this overhardening doesn't give us any benefit. However under-hardening can hurt us.\n",
    "\n",
    "* 8 substations are under hardened. Out of these 5 substations were not hardened at all. Now, if flooding at these substations in some of the cases is less than 6 feet, we will protect them using tiger dams. This requires buying extra tiger dams. Infact model purchases 24 extra tiger dam units which is reflected in extra tiger dam cost. Two out of these 5 substations have max flood level > 6 feet and therefore they also lead to extra load shed. For other 3 substations, the hardening level of the non-binary model is 12 feet whereas their max flood level is 13,15, and 16 feet. So even in this case, there is extra load shed. \n",
    "\n",
    "* If all these 8 substations are hardened to avoid load shed, it will cost 4.5M but, we loss net power worth 2.7M. So, that is why solution is what it is.\n",
    "\n",
    "* 35 have same hardening level. So nothing to think about here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f8a401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef6757c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4e6c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1541e5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cdfb63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
