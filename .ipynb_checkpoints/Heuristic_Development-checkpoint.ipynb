{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hollow-kernel",
   "metadata": {},
   "source": [
    "* At very high costs, deployments would be come very expensive and hardening would be better even for prep_enough\n",
    "* At what frequency level, it would become sensible to harden than to protect\n",
    "\n",
    "* make a plot of substations which are flooded with max height of more than prep_level and have highest frequency of such flooding.\n",
    "\n",
    "\n",
    "* For prep_enough, preparedness always better than hardening.\n",
    "\n",
    "## Heuristic process:\n",
    "\n",
    "* Only filter flooded substations, for rest set corresponding x,y,z to fixed values\n",
    "* For the 72 flooded substations,\n",
    "    * If max_flood <= max_prep:\n",
    "        * These (24 substations) can be protected from just tiger dams, so set their x,y = 0\n",
    "    * For rest of (72-24 = 48 substations):\n",
    "        * Compute hardening cost\n",
    "        \n",
    "## Knapsacking in the presence of budget constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "improved-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from three_stage_model import *\n",
    "pd.set_option('display.max_rows',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "robust-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_for_heuristic():\n",
    "    df = pd.read_csv(\"/home1/07346/ashukla/ThreeStageModel/data/192_Scenario/Final_Input1.csv\")\n",
    "    directions = [\"w\", \"wnw\", \"nw\", \"nnw\", \"n\", \"nne\"]\n",
    "    categories = [\"2\", \"3\", \"4\", \"5\"]\n",
    "    forward_speeds = [\"05\", \"10\", \"15\", \"25\"]\n",
    "    lister = []\n",
    "    for i in directions:\n",
    "        for j in range(len(categories)):\n",
    "            for k in range(len(forward_speeds)):\n",
    "                lister.append(\"max_flood_level_\" + i +\"_\" + categories[j] + \"_\" + forward_speeds[k])\n",
    "    df = df[list(df.columns[0:9]) + lister]\n",
    "    df_sub = df[[\"SubNum\", \"load\"]].groupby(\"SubNum\").sum()\n",
    "    df_flood = df[[\"SubNum\"] + lister]\n",
    "    df_flood = df_flood.drop_duplicates().set_index(\"SubNum\") # drop duplicates\n",
    "    df_flood = df_flood.loc[(df_flood.sum(axis=1) != 0), :] # drop substations that are not flooded\n",
    "    \"\"\"df_sub has load demand for all the substations\"\"\"\n",
    "    \"\"\"df_flood has only flooded substations\"\"\"\n",
    "    return df, df_sub, df_flood\n",
    "\n",
    "def flood_info_generator(model_scenarios, df_flood):\n",
    "    \"\"\"Dictionary flood_info contains information on how frequently was each substation flooded \n",
    "    in each mini-Brent case. They key is substation id. The value is another dictionary whose each \n",
    "    entry is mini-Brent model id. And the value of this dictionary is how many scenarios \n",
    "    within this mini-brent model was that substation flooded.\"\"\"\n",
    "    flood_info = {}\n",
    "    for i in df_flood.index:\n",
    "        flood_info[i] = {}\n",
    "        for j in model_scenarios:\n",
    "            counter = 0\n",
    "            for k in model_scenarios[j]:\n",
    "                if df_flood.loc[i, k] > 0:\n",
    "                    counter = counter + 1\n",
    "            flood_info[i][j] = counter\n",
    "    return flood_info\n",
    "\n",
    "def compute_load_shed_no_measure(flood_info, df_sub, model_scenarios, params, df_flood):\n",
    "    expected_load_shed = {}\n",
    "    for i in flood_info:\n",
    "        load_value = df_sub.loc[i,\"load\"]\n",
    "        temp = 0\n",
    "        for j in flood_info[i]:\n",
    "            \"\"\"We see in how many leaves out of 216 it is flooded\"\"\"\n",
    "            temp = temp + load_value*flood_info[i][j]\n",
    "        expected_load_shed[i] = temp/(len(model_scenarios.keys())*len(model_scenarios[0]))\n",
    "        expected_load_shed[i] = [round(expected_load_shed[i]*params[\"voll\"]*params[\"restore_time\"]*params[\"tau\"]/1e6,3), df_flood.loc[i,:].max()]\n",
    "    main_df = pd.DataFrame(expected_load_shed).T\n",
    "    main_df.columns = [\"voll_million\", \"max_flood\"]\n",
    "    main_df[\"prepare_million\"] = 1e12\n",
    "    main_df[\"mitigate_million\"] = 1e12\n",
    "    \"\"\"Note that: Every substation in main_df is flooded atleast once\"\"\"\n",
    "    for i in main_df.index:\n",
    "        hardening_cost = params[\"fixed_cost\"] + params[\"variable_cost\"]*main_df.loc[i, \"max_flood\"]\n",
    "        main_df.loc[i, \"mitigate_million\"] = round(hardening_cost/1e6, 3)\n",
    "    return main_df\n",
    "\n",
    "def prep_cost_computer(prep_enough, flood_info, params, model_scenarios):\n",
    "    for i in prep_enough.index:\n",
    "        temp = 0 # temp is counter of number of mini-brent cases when tiger dams need to be deployed\n",
    "        for j in flood_info[i]:\n",
    "            if flood_info[i][j] > 0:\n",
    "                temp = temp + 1\n",
    "        temp = temp/len(model_scenarios.keys())\n",
    "        temp = temp*params[\"operating_cost\"]*params[\"tau\"]\n",
    "        prep_enough.loc[i, \"prepare_million\"] = round((prep_enough.loc[i, \"max_flood\"]*params[\"td_cost\"] + temp)/1e6, 3)\n",
    "    return prep_enough\n",
    "\n",
    "def mit_prep_fixable_substation(mit_enough, df_flood, params):\n",
    "    temp_df = df_flood.loc[mit_enough.index,:].copy() # only mit indices will be present\n",
    "    temp_df = temp_df[(temp_df > 0) & (temp_df <= params[\"prep_level\"])]\n",
    "    temp_df = temp_df.dropna(thresh=1)\n",
    "    can_be_fixed = list(temp_df.index)\n",
    "    return can_be_fixed\n",
    "\n",
    "def mit_cost_computer(mit_enough, params, flood_info, model_scenarios, df_flood, df_sub):\n",
    "    \"\"\"For each substation deploy_count counts the number of times, deployment happened in mini-brent models. \n",
    "    load_loss counts the number of times flooding happened\"\"\"\n",
    "    deploy_count = {} \n",
    "    load_loss = {}\n",
    "    for i in mit_enough.index:\n",
    "        deploy_count[i] = 0\n",
    "        load_loss[i] = 0\n",
    "        max_preventable_flooding = 0\n",
    "        for j in flood_info[i]:\n",
    "            flag = 0\n",
    "            for k in model_scenarios[j]:\n",
    "                flood_level = df_flood.loc[i,k]\n",
    "                if (flood_level > 0) & (flood_level <= params[\"prep_level\"]):\n",
    "                    flag = 1\n",
    "                    if flood_level > max_preventable_flooding:\n",
    "                        max_preventable_flooding = flood_level\n",
    "                if flood_level > params[\"prep_level\"]:\n",
    "                    load_loss[i] = load_loss[i] + 1\n",
    "            deploy_count[i] = deploy_count[i] + flag\n",
    "        deploy_count[i] = [deploy_count[i], max_preventable_flooding]\n",
    "    for i in deploy_count:\n",
    "        deploy_count[i].append(load_loss[i])\n",
    "    mitigate = pd.DataFrame(deploy_count).T\n",
    "    mitigate.columns = [\"deploy_counts\", \"max_td_units\", \"load_loss_flood_counts\"]\n",
    "    \n",
    "    for i in mitigate.index:\n",
    "        O_C = (mitigate.loc[i,\"deploy_counts\"]/len(model_scenarios.keys()))*params[\"operating_cost\"]*params[\"tau\"]\n",
    "        V_C = mitigate.loc[i,\"load_loss_flood_counts\"]/(len(model_scenarios.keys())*len(model_scenarios[0]))\n",
    "        V_C = V_C*df_sub.loc[i,\"load\"]*params[\"voll\"]*params[\"restore_time\"]*params[\"tau\"]\n",
    "        A_C = params[\"td_cost\"]*mitigate.loc[i,\"max_td_units\"]\n",
    "        T_C = O_C + V_C + A_C\n",
    "        T_C = round(T_C/1e6,3)\n",
    "        mit_enough.loc[i, \"prepare_million\"] = T_C    \n",
    "    return mitigate, mit_enough\n",
    "\n",
    "def heuristic(df_type, flood_info, df_flood, model_scenarios, params):\n",
    "    heuristic_dictionary = {}\n",
    "    for i in df_type.index:\n",
    "        heuristic_dictionary[i] = {}\n",
    "        min_value = min(df_type.loc[i,\"voll_million\"], \n",
    "                        min(df_type.loc[i,\"prepare_million\"], df_type.loc[i,\"mitigate_million\"]))\n",
    "        if min_value == df_type.loc[i,\"prepare_million\"]:\n",
    "            heuristic_dictionary[i][\"x_mit\"] = 0\n",
    "            heuristic_dictionary[i][\"y_mit\"] = 0\n",
    "            for j in flood_info[i]:\n",
    "                if flood_info[i][j] > 0:\n",
    "                    # here we check that for flooded substation, can it be protected with tiger dams\n",
    "                    flag = 0\n",
    "                    max_preventable_flooding = 0\n",
    "                    for k in model_scenarios[j]:\n",
    "                        flood_level = df_flood.loc[i,k]\n",
    "                        if (flood_level > 0) & (flood_level <= params[\"prep_level\"]):\n",
    "                            flag = 1\n",
    "                            if flood_level > max_preventable_flooding:\n",
    "                                max_preventable_flooding = flood_level\n",
    "                    # So if in any one scenario, flooding can be prevented with tiger dams, we will protect\n",
    "                    if flag == 1:\n",
    "                        heuristic_dictionary[i][\"p_\" + str(j)] = max_preventable_flooding\n",
    "                        heuristic_dictionary[i][\"q_\" + str(j)] = 1\n",
    "                    else:\n",
    "                        # in this case, there is flooding but it cannot be prevented\n",
    "                        heuristic_dictionary[i][\"p_\" + str(j)] = 0\n",
    "                        heuristic_dictionary[i][\"q_\" + str(j)] = 0   \n",
    "                else:\n",
    "                    heuristic_dictionary[i][\"p_\" + str(j)] = 0\n",
    "                    heuristic_dictionary[i][\"q_\" + str(j)] = 0  \n",
    "        elif min_value == df_type.loc[i,\"mitigate_million\"]:\n",
    "            heuristic_dictionary[i][\"x_mit\"] = df_type.loc[i, \"max_flood\"]\n",
    "            heuristic_dictionary[i][\"y_mit\"] = 1\n",
    "            for j in flood_info[i]:  \n",
    "                heuristic_dictionary[i][\"p_\" + str(j)] = 0\n",
    "                heuristic_dictionary[i][\"q_\" + str(j)] = 0\n",
    "        else:\n",
    "            heuristic_dictionary[i][\"x_mit\"] = 0\n",
    "            heuristic_dictionary[i][\"y_mit\"] = 0\n",
    "            for j in flood_info[i]:\n",
    "                heuristic_dictionary[i][\"p_\" + str(j)] = 0\n",
    "                heuristic_dictionary[i][\"q_\" + str(j)] = 0\n",
    "    return heuristic_dictionary\n",
    "\n",
    "def tighten_model(df_sub, df_flood, flood_info, model_scenarios):\n",
    "    heuristic_dictionary = {}\n",
    "    flood_list = list(df_flood.index)\n",
    "    for i in df_sub.index:\n",
    "        if i not in flood_list:\n",
    "            heuristic_dictionary[i] = {}\n",
    "            heuristic_dictionary[i][\"x_mit\"] = 0\n",
    "            heuristic_dictionary[i][\"y_mit\"] = 0\n",
    "            for j in model_scenarios:\n",
    "                heuristic_dictionary[i][\"p_\" + str(j)] = 0\n",
    "                heuristic_dictionary[i][\"q_\" + str(j)] = 0\n",
    "        else:\n",
    "            continue\n",
    "    return heuristic_dictionary\n",
    "\n",
    "def final_heuristic(flood_info, df_sub, model_scenarios, params, df_flood):\n",
    "    main_df = compute_load_shed_no_measure(flood_info, df_sub, model_scenarios, params, df_flood)\n",
    "    prep_enough = main_df[(main_df[\"max_flood\"] <= params[\"prep_level\"])].copy()\n",
    "    mit_enough = main_df[(main_df[\"max_flood\"] > params[\"prep_level\"])].copy()\n",
    "    prep_enough = prep_enough[['voll_million', 'prepare_million', 'mitigate_million', 'max_flood']]\n",
    "    mit_enough = mit_enough[['voll_million', 'prepare_million', 'mitigate_million', 'max_flood']]\n",
    "    prep_enough = prep_cost_computer(prep_enough, flood_info, params, model_scenarios)\n",
    "    mitigate, mit_enough = mit_cost_computer(mit_enough, params, flood_info, model_scenarios, df_flood, df_sub)\n",
    "    prep_dict = heuristic(prep_enough, flood_info, df_flood, model_scenarios, params)\n",
    "    mit_dict = heuristic(mit_enough, flood_info, df_flood, model_scenarios, params)\n",
    "    rest_dict = tighten_model(df_sub, df_flood, flood_info, model_scenarios)\n",
    "    return prep_dict, mit_dict, rest_dict\n",
    "\n",
    "def opt_solution_reader(model_scenarios, voll_value, path_str, df_flood):\n",
    "    main_path = path_str + str(voll_value) + \"/\"\n",
    "    with open(main_path + \"model_params.json\", 'r') as f:\n",
    "        params = json.load(f)   \n",
    "    params[\"path_to_input\"] = os.getcwd() + \"/data/192_Scenario/\"\n",
    "    base_model = three_stage_model(params, model_scenarios)\n",
    "    base_model.model.update()\n",
    "    sol_path = main_path + \"solution.sol\"\n",
    "    base_model.model.read(sol_path)\n",
    "    base_model.model.update()\n",
    "    \n",
    "    hardening_decisions = {}\n",
    "    tiger_dam_decisions = {}\n",
    "    \n",
    "    for sub_id in df_flood.index:\n",
    "        hardening_decisions[sub_id] = int(base_model.x_mit[sub_id].Start*params[\"mit_level\"])\n",
    "    for sub_id in df_flood.index:\n",
    "        for j in model_scenarios:\n",
    "            tiger_dam_decisions[str(sub_id) + \"_\" + str(j)] = int(base_model.x_prep[sub_id,j].Start*params[\"prep_level\"])\n",
    "    \n",
    "    return hardening_decisions, tiger_dam_decisions\n",
    "\n",
    "def post_process_heuristic_output(voll_list, flood_info, df_sub, model_scenarios, params, df_flood):\n",
    "    heuristic_solution_dictionary = {}\n",
    "    for voll_value in voll_list:\n",
    "        params[\"voll\"] = voll_value\n",
    "        prep_dict, mit_dict, rest_dict = final_heuristic(flood_info, df_sub, model_scenarios, params, df_flood)    \n",
    "        h = {}\n",
    "        for i in df_flood.index:\n",
    "            if i in prep_dict:\n",
    "                h[i] = int(prep_dict[i]['x_mit'])\n",
    "            else:\n",
    "                h[i] = int(mit_dict[i]['x_mit'])\n",
    "        t = {}\n",
    "        for i in df_flood.index:\n",
    "            for j in model_scenarios:\n",
    "                if i in prep_dict:\n",
    "                    t[str(i) + \"_\" + str(j)] = prep_dict[i][\"p_\" + str(j)]\n",
    "                else:\n",
    "                    t[str(i) + \"_\" + str(j)] = mit_dict[i][\"p_\" + str(j)]\n",
    "        heuristic_solution_dictionary[voll_value] = [h,t]\n",
    "    return heuristic_solution_dictionary\n",
    "\n",
    "def heuristic_hardening_score(voll_list, df_flood, heuristic_solution_dictionary, optimization_solution_list):\n",
    "    df_list = []\n",
    "    for voll in voll_list:\n",
    "        zeros = 0\n",
    "        match = 0\n",
    "        unmatch = 0\n",
    "        for i in df_flood.index:\n",
    "            t1 = heuristic_solution_dictionary[voll][0][i]\n",
    "            t2 = optimization_solution_list[voll][0][i]    \n",
    "            if (t1 == t2):\n",
    "                if t1 == 0:\n",
    "                    zeros = zeros + 1\n",
    "                else:\n",
    "                    match = match + 1\n",
    "            else:\n",
    "                unmatch = unmatch + 1\n",
    "        df_list.append([voll, zeros, match, unmatch])\n",
    "    df_list = pd.DataFrame(df_list)\n",
    "    df_list.columns = [\"voll\", \"zeros\", \"match\", \"unmatch\"]\n",
    "    df_list = df_list.set_index(\"voll\")\n",
    "    return df_list\n",
    "\n",
    "def heuristic_td_score(voll_list, df_flood, model_scenarios, heuristic_solution, optimization_list):\n",
    "    df_list = []\n",
    "    mismatch = {}\n",
    "    for voll in voll_list:\n",
    "        mismatch[voll] = {}\n",
    "        zeros = 0\n",
    "        match = 0\n",
    "        unmatch = 0\n",
    "        for i in df_flood.index:\n",
    "            for j in model_scenarios:\n",
    "                t1 = heuristic_solution[voll][1][str(i) + \"_\" + str(j)]\n",
    "                t2 = optimization_list[voll][1][str(i) + \"_\" + str(j)]    \n",
    "                if (t1 == t2):\n",
    "                    if t1 == 0:\n",
    "                        zeros = zeros + 1\n",
    "                    else:\n",
    "                        match = match + 1\n",
    "                else:\n",
    "                    if ((t1 > 0) & (t1 <= 6) & (t2 == 6)):\n",
    "                        match = match + 1\n",
    "                    else:\n",
    "                        if i not in mismatch[voll]:\n",
    "                            mismatch[voll][i] = {}\n",
    "                            mismatch[voll][i][j] = [t1,t2]\n",
    "                        else:\n",
    "                            mismatch[voll][i][j] = [t1,t2]\n",
    "                        unmatch = unmatch + 1\n",
    "        df_list.append([voll, zeros, match, unmatch])\n",
    "    df_list = pd.DataFrame(df_list)\n",
    "    df_list.columns = [\"voll\", \"zeros\", \"match\", \"unmatch\"]\n",
    "    df_list = df_list.set_index(\"voll\")\n",
    "    return df_list, mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-mitchell",
   "metadata": {},
   "source": [
    "## Heuristic Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "falling-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scenarios = return_model_scenarios()\n",
    "df, df_sub, df_flood = get_df_for_heuristic()\n",
    "flood_info = flood_info_generator(model_scenarios, df_flood)\n",
    "path_str = \"/work2/07346/ashukla/stampede2/ThreeStageModel/output/modified_td_voll_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adaptive-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization_solution_list = {}\n",
    "# voll_list = [250,500,1000,2000,3000,4000,5000,6000]\n",
    "\n",
    "# for voll_value in voll_list:\n",
    "#     print(\"Voll value processed is\\t\", voll_value)\n",
    "#     h, t = opt_solution_reader(model_scenarios, voll_value, path_str, df_flood)\n",
    "#     optimization_solution_list[voll_value] = [h,t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "soviet-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('optimization_solution_list.pickle', 'wb') as handle:\n",
    "#     pickle.dump(optimization_solution_list, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "electoral-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('optimization_solution_list.pickle', 'rb') as handle:\n",
    "    optimization_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-breach",
   "metadata": {},
   "source": [
    "### Heuristic solution computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "assumed-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'multi.yaml') as file:\n",
    "    params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "params[\"td_cost\"] = 40000\n",
    "params[\"operating_cost\"] = 10000\n",
    "\n",
    "voll_list = [250,500,1000,2000,3000,4000,5000,6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "advisory-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic_solution = post_process_heuristic_output(voll_list, flood_info, df_sub, \n",
    "                                                              model_scenarios, params, df_flood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "separate-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "hardening_score = heuristic_hardening_score(voll_list, df_flood, heuristic_solution, optimization_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "distinguished-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_score, mismatch = heuristic_td_score(voll_list, df_flood, model_scenarios, heuristic_solution, optimization_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "involved-andorra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zeros</th>\n",
       "      <th>match</th>\n",
       "      <th>unmatch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voll</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>42</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>29</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>25</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>24</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      zeros  match  unmatch\n",
       "voll                       \n",
       "250      50     17        5\n",
       "500      42     28        2\n",
       "1000     35     32        5\n",
       "2000     29     38        5\n",
       "3000     27     29       16\n",
       "4000     25     43        4\n",
       "5000     25     33       14\n",
       "6000     24     44        4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hardening_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "arbitrary-maria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zeros</th>\n",
       "      <th>match</th>\n",
       "      <th>unmatch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voll</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>3029</td>\n",
       "      <td>561</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>3295</td>\n",
       "      <td>499</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>3399</td>\n",
       "      <td>316</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>3585</td>\n",
       "      <td>238</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>3674</td>\n",
       "      <td>189</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>3683</td>\n",
       "      <td>185</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>3707</td>\n",
       "      <td>161</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>3707</td>\n",
       "      <td>161</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      zeros  match  unmatch\n",
       "voll                       \n",
       "250    3029    561      298\n",
       "500    3295    499       94\n",
       "1000   3399    316      173\n",
       "2000   3585    238       65\n",
       "3000   3674    189       25\n",
       "4000   3683    185       20\n",
       "5000   3707    161       20\n",
       "6000   3707    161       20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-learning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
