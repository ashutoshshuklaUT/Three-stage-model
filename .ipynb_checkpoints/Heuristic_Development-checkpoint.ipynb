{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hollow-kernel",
   "metadata": {},
   "source": [
    "* At very high costs, deployments would be come very expensive and hardening would be better even for prep_enough\n",
    "* At what frequency level, it would become sensible to harden than to protect\n",
    "\n",
    "* make a plot of substations which are flooded with max height of more than prep_level and have highest frequency of such flooding.\n",
    "\n",
    "\n",
    "* For prep_enough, preparedness always better than hardening.\n",
    "\n",
    "## Heuristic process:\n",
    "\n",
    "* Only filter flooded substations, for rest set corresponding x,y,z to fixed values\n",
    "* For the 72 flooded substations,\n",
    "    * If max_flood <= max_prep:\n",
    "        * These (24 substations) can be protected from just tiger dams, so set their x,y = 0\n",
    "    * For rest of (72-24 = 48 substations):\n",
    "        * Compute hardening cost\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "improved-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import yaml\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows',500)\n",
    "\n",
    "with open(r'multi.yaml') as file:\n",
    "    params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "params[\"td_cost\"] = 40000\n",
    "params[\"voll\"] = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afraid-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_for_heuristic():\n",
    "    df = pd.read_csv(\"/home1/07346/ashukla/ThreeStageModel/data/192_Scenario/Final_Input1.csv\")\n",
    "    directions = [\"w\", \"wnw\", \"nw\", \"nnw\", \"n\", \"nne\"]\n",
    "    categories = [\"2\", \"3\", \"4\", \"5\"]\n",
    "    forward_speeds = [\"05\", \"10\", \"15\", \"25\"]\n",
    "    lister = []\n",
    "    for i in directions:\n",
    "        for j in range(len(categories)):\n",
    "            for k in range(len(forward_speeds)):\n",
    "                lister.append(\"max_flood_level_\" + i +\"_\" + categories[j] + \"_\" + forward_speeds[k])\n",
    "    df = df[list(df.columns[0:9]) + lister]\n",
    "    df_sub = df[[\"SubNum\", \"load\"]].groupby(\"SubNum\").sum()\n",
    "    df_flood = df[[\"SubNum\"] + lister]\n",
    "    df_flood = df_flood.drop_duplicates().set_index(\"SubNum\") # drop duplicates\n",
    "    df_flood = df_flood.loc[(df_flood.sum(axis=1) != 0), :] # drop substations that are not flooded\n",
    "    \"\"\"df_sub has load demand for all the substations\"\"\"\n",
    "    \"\"\"df_flood has only flooded substations\"\"\"\n",
    "    return df, df_sub, df_flood\n",
    "\n",
    "def flood_info_generator(model_scenarios, df_flood):\n",
    "    \"\"\"Dictionary flood_info contains information on how frequently was each substation flooded \n",
    "    in each mini-Brent case. They key is substation id. The value is another dictionary whose each \n",
    "    entry is mini-Brent model id. And the value of this dictionary is how many scenarios \n",
    "    within this mini-brent model was that substation flooded.\"\"\"\n",
    "    flood_info = {}\n",
    "    for i in df_flood.index:\n",
    "        flood_info[i] = {}\n",
    "        for j in model_scenarios:\n",
    "            counter = 0\n",
    "            for k in model_scenarios[j]:\n",
    "                if df_flood.loc[i, k] > 0:\n",
    "                    counter = counter + 1\n",
    "            flood_info[i][j] = counter\n",
    "    return flood_info\n",
    "\n",
    "def compute_load_shed_no_measure(flood_info, df_sub, model_scenarios, params, df_flood):\n",
    "    expected_load_shed = {}\n",
    "    for i in flood_info:\n",
    "        load_value = df_sub.loc[i,\"load\"]\n",
    "        temp = 0\n",
    "        for j in flood_info[i]:\n",
    "            \"\"\"We see in how many leaves out of 216 it is flooded\"\"\"\n",
    "            temp = temp + load_value*flood_info[i][j]\n",
    "        expected_load_shed[i] = temp/(len(model_scenarios.keys())*len(model_scenarios[0]))\n",
    "        expected_load_shed[i] = [round(expected_load_shed[i]*params[\"voll\"]*params[\"restore_time\"]*params[\"tau\"]/1e6,3), df_flood.loc[i,:].max()]\n",
    "    main_df = pd.DataFrame(expected_load_shed).T\n",
    "    main_df.columns = [\"voll_million\", \"max_flood\"]\n",
    "    main_df[\"prepare_million\"] = 1000\n",
    "    main_df[\"mitigate_million\"] = 1000\n",
    "    \"\"\"Every substation in main_df is flooded atleast once\"\"\"\n",
    "    for i in main_df.index:\n",
    "        hardening_cost = params[\"fixed_cost\"] + params[\"variable_cost\"]*main_df.loc[i, \"max_flood\"]\n",
    "        main_df.loc[i, \"mitigate_million\"] = round(hardening_cost/1e6, 3)\n",
    "    return main_df\n",
    "\n",
    "def prep_cost_computer(prep_enough, flood_info, params):\n",
    "    for i in prep_enough.index:\n",
    "        temp = 0 # temp is counter of number of mini-brent cases when tiger dams need to be deployed\n",
    "        for j in flood_info[i]:\n",
    "            if flood_info[i][j] > 0:\n",
    "                temp = temp + 1\n",
    "        temp = temp/len(model_scenarios.keys())\n",
    "        temp = temp*params[\"operating_cost\"]*params[\"tau\"]\n",
    "        prep_enough.loc[i, \"prepare_million\"] = round((prep_enough.loc[i, \"max_flood\"]*params[\"td_cost\"] + temp)/1e6, 3)\n",
    "    \n",
    "    return prep_enough\n",
    "\n",
    "def mit_prep_fixable_substation(mit_enough, df_flood, params):\n",
    "    temp_df = df_flood.loc[mit_enough.index,:].copy()\n",
    "    temp_df = temp_df[(temp_df > 0) & (temp_df <= params[\"prep_level\"])]\n",
    "    temp_df = temp_df.dropna(thresh=1)\n",
    "    can_be_fixed = list(temp_df.index)\n",
    "    return can_be_fixed\n",
    "\n",
    "def mit_cost_computer(mit_enough, params, flood_info, model_scenarios, df_flood, df_sub):\n",
    "    \"\"\"For each substation deploy_count counts the number of times, deployment happened in mini-brent models. \n",
    "    load_loss counts the number of times flooding happened\"\"\"\n",
    "    deploy_count = {} \n",
    "    load_loss = {}\n",
    "    for i in mit_enough.index:\n",
    "        deploy_count[i] = 0\n",
    "        load_loss[i] = 0\n",
    "        max_preventable_flooding = 0\n",
    "        for j in flood_info[i]:\n",
    "            flag = 0\n",
    "            for k in model_scenarios[j]:\n",
    "                flood_level = df_flood.loc[i,k]\n",
    "                if (flood_level > 0) & (flood_level <= params[\"prep_level\"]):\n",
    "                    flag = 1\n",
    "                    if flood_level > max_preventable_flooding:\n",
    "                        max_preventable_flooding = flood_level\n",
    "                if flood_level > params[\"prep_level\"]:\n",
    "                    load_loss[i] = load_loss[i] + 1\n",
    "            deploy_count[i] = deploy_count[i] + flag\n",
    "        deploy_count[i] = [deploy_count[i], max_preventable_flooding]\n",
    "    for i in deploy_count:\n",
    "        deploy_count[i].append(load_loss[i])\n",
    "    mitigate = pd.DataFrame(deploy_count).T\n",
    "    mitigate.columns = [\"deploy_counts\", \"max_td_units\", \"load_loss_flood_counts\"]\n",
    "    \n",
    "    for i in mitigate.index:\n",
    "        O_C = (mitigate.loc[i,\"deploy_counts\"]/len(model_scenarios.keys()))*params[\"operating_cost\"]*params[\"tau\"]\n",
    "        V_C = mitigate.loc[i,\"load_loss_flood_counts\"]/(len(model_scenarios.keys())*len(model_scenarios[0]))\n",
    "        V_C = V_C*df_sub.loc[i,\"load\"]*params[\"voll\"]*params[\"restore_time\"]*params[\"tau\"]\n",
    "        A_C = params[\"td_cost\"]*mitigate.loc[i,\"max_td_units\"]\n",
    "        T_C = O_C + V_C + A_C\n",
    "        T_C = round(T_C/1e6,3)\n",
    "        mit_enough.loc[i, \"prepare_million\"] = T_C    \n",
    "    return mitigate, mit_enough\n",
    "\n",
    "def heuristic(df_type, flood_info, df_flood, model_scenarios, params):\n",
    "    heuristic_dictionary = {}\n",
    "    for i in df_type.index:\n",
    "        heuristic_dictionary[i] = {}\n",
    "        min_value = min(df_type.loc[i,\"voll_million\"], \n",
    "                        min(df_type.loc[i,\"prepare_million\"], df_type.loc[i,\"mitigate_million\"]))\n",
    "        if min_value == df_type.loc[i,\"prepare_million\"]:\n",
    "            heuristic_dictionary[i][\"x_mit\"] = 0\n",
    "            heuristic_dictionary[i][\"y_mit\"] = 0\n",
    "            for j in flood_info[i]:\n",
    "                if flood_info[i][j] > 0:\n",
    "                    flag = 0\n",
    "                    max_preventable_flooding = 0\n",
    "                    for k in model_scenarios[j]:\n",
    "                        flood_level = df_flood.loc[i,k]\n",
    "                        if (flood_level > 0) & (flood_level <= params[\"prep_level\"]):\n",
    "                            flag = 1\n",
    "                            if flood_level > max_preventable_flooding:\n",
    "                                max_preventable_flooding = flood_level\n",
    "                    if flag == 1:\n",
    "                        heuristic_dictionary[i][\"p_\" + str(j)] = max_preventable_flooding\n",
    "                        heuristic_dictionary[i][\"q_\" + str(j)] = 1\n",
    "                    else:\n",
    "                        heuristic_dictionary[i][\"p_\" + str(j)] = 0\n",
    "                        heuristic_dictionary[i][\"q_\" + str(j)] = 0   \n",
    "                else:\n",
    "                    heuristic_dictionary[i][\"p_\" + str(j)] = 0\n",
    "                    heuristic_dictionary[i][\"q_\" + str(j)] = 0  \n",
    "        elif min_value == df_type.loc[i,\"mitigate_million\"]:\n",
    "            heuristic_dictionary[i][\"x_mit\"] = df_type.loc[i, \"max_flood\"]\n",
    "            heuristic_dictionary[i][\"y_mit\"] = 1\n",
    "            for j in flood_info[i]:  \n",
    "                heuristic_dictionary[i][\"p_\" + str(j)] = 0\n",
    "                heuristic_dictionary[i][\"q_\" + str(j)] = 0\n",
    "        else:\n",
    "            heuristic_dictionary[i][\"x_mit\"] = 0\n",
    "            heuristic_dictionary[i][\"y_mit\"] = 0\n",
    "            for j in flood_info[i]:\n",
    "                heuristic_dictionary[i][\"p_\" + str(j)] = 0\n",
    "                heuristic_dictionary[i][\"q_\" + str(j)] = 0\n",
    "    return heuristic_dictionary\n",
    "\n",
    "def tighten_model(df_sub, df_flood, flood_info, model_scenarios):\n",
    "    heuristic_dictionary = {}\n",
    "    flood_list = list(df_flood.index)\n",
    "    for i in df_sub.index:\n",
    "        if i not in flood_list:\n",
    "            heuristic_dictionary[i] = {}\n",
    "            heuristic_dictionary[i][\"x_mit\"] = 0\n",
    "            heuristic_dictionary[i][\"y_mit\"] = 0\n",
    "            for j in model_scenarios:\n",
    "                heuristic_dictionary[i][\"p_\" + str(j)] = 0\n",
    "                heuristic_dictionary[i][\"q_\" + str(j)] = 0\n",
    "        else:\n",
    "            continue\n",
    "    return heuristic_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-mitchell",
   "metadata": {},
   "source": [
    "## Heuristic_Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adaptive-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scenarios = return_model_scenarios()\n",
    "df, df_sub, df_flood = get_df_for_heuristic()\n",
    "flood_info = flood_info_generator(model_scenarios, df_flood)\n",
    "main_df = compute_load_shed_no_measure(flood_info, df_sub, model_scenarios, params, df_flood)\n",
    "\n",
    "prep_enough = main_df[(main_df[\"max_flood\"] <= params[\"prep_level\"])].copy()\n",
    "mit_enough = main_df[(main_df[\"max_flood\"] > params[\"prep_level\"])].copy()\n",
    "prep_enough = prep_enough[['voll_million', 'prepare_million', 'mitigate_million', 'max_flood']]\n",
    "mit_enough = mit_enough[['voll_million', 'prepare_million', 'mitigate_million', 'max_flood']]\n",
    "\n",
    "prep_enough = prep_cost_computer(prep_enough, flood_info, params)\n",
    "mitigate, mit_enough = mit_cost_computer(mit_enough, params, flood_info, model_scenarios, df_flood, df_sub)\n",
    "\n",
    "prep_dict = heuristic(prep_enough, flood_info, df_flood, model_scenarios, params)\n",
    "mit_dict = heuristic(mit_enough, flood_info, df_flood, model_scenarios, params)\n",
    "rest_dict = tighten_model(df_sub, df_flood, flood_info, model_scenarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-demand",
   "metadata": {},
   "source": [
    "## Knapsacking in the presence of budget constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-indonesia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
